# 3. Research designs 
### Introduction 
Besides the decision about the research strategy, also two other key decisions will have to be made: research design and research method.

### Research method: simply a technique for collecting data 
- It can involve a specific instrument, such as a self-completion questionnaire or a structured interview schedule or participant observation whereby researcher listens to others Research design: provides a framework for the collection and analysis of data
- Choice of research design reflects decisions about the priority being given to a range of dimensions of the research process 
- These include the importance attached to 
	- expressing causal connections between variables 
	- generalizing to larger groups than those actually forming part of investigation 
	- understanding behavior and meaning of that behavior in its specific context 
	- having a temporal appreciation of social phenomena and their interconnections 

### Quality criteria in business research
Three of the most prominent criteria for evaluation of business and management research are 
- Reliability: whether or not the measures are consistent 
	- The question of whether the results of a study are repeatable 
	- Particular concern in quantitative research 
- Replicability: 
	- In order to assess the reliability of a measure of a concept, the procedures that constitute that measure must be replicable by someone else 
	- Researcher needs to spell out his or her procedures in great detail
- Validity: how well an instrument measures what it is intended to measure 
	- Measurement (or construct) validity: does a measure capture the phenomenon which it is intended to capture? (e.g. IQ for intelligence) -> relates to reliability 
	- Internal validity: are causal relations between variables real? (e.g. does rising amount of storks in cities influence the rising birth-rate in cities or not?) -> relates to causality 
	- External validity: can results be generalized beyond the research context? (e.g. does a study on HRM within the Coca Cola company also apply on Procter and Gamble?) 
	- Ecological validity: are social scientific findings applicable in everyday? (e.g. questionnaire might be filled in different than how it goes in real life)

These methods have mainly to do with quantitative research. However, ecological validity have relevance to both quantitative and qualitative research. 

Alternative criteria in qualitative research (because the above are inapplicable and inappropriate for qualitative research): Trustworthiness consists of four criteria, which has an equivalent criterion in quantitative research 
- Credibility: parallels internal validity - how believable are the findings?
- Transferability: parallels external validity - do the findings apply to other contexts? 
- Dependability: parallels reliability - are the findings likely to apply at other times? 
- Confirmability: parallels objectivity - has the investigator allowed his/her values to intrude to a high degree? 

A possible type that can be added to the list would be relevance (is the topic of contribution to the existing literature in this field?).

Quantitative research is often based on principles of naturalism, which means that the researcher seeks to collect data in naturally occurring situations and environments. 

### Research designs 
Five different types will be examined: 
- Experimental design 
- Cross-sectional or social survey design 
- Longitudinal design 
- Case study design 
- Comparative design 

### Experimental design: laboratory and field experiments 
True field experiments are relatively rare in business and management research. True experiments tend to be very strong in terms of internal validity. 

### Quantitative: 
In order to conduct a true experiment, it is necessary to manipulate the independent variable in order to determine whether it has an influence on the dependent variable. 
- Dependent (not manipulated) and independent (manipulated) 
- During an experiment you always make two experiment groups that are each going to be tested on different levels of an independent variable. However, often variables with which business cases are concerned, cannot be manipulated (entails intervening in a situation to determine which of two things happens to subjects). 

It is more common to find field experiments in which a scenario is employed as a substitute for a real life setting and not laboratory experiments where experiments take place in laboratories and artificial environment where conditions are much easier to control. 

Classical experimental design = two groups are established, which forms basis for experimental manipulation of independent variable 
- The experimental group, or treatment group, receives the treatment and it is compared against the control group, who does not receive the treatment. 
- Dependent variable is measured before and after the treatment, a before-and-after analysis can be conducted

5 major treats of internal validity with experimental design: 
- Testing - the possibility that subjects may become sensitized to the aims of the experiment 
- History - the possibility that events in the experimental environment that are unrelated to manipulation of the independent variable may have caused the changes 
- Maturation - people can change along the research 
- Selection - if they are chosen randomly changes can arise between control and experimental group 
- Ambiguity about the direction of causal influence - there might be no connection between independent and dependent variable
Presence of a control group coupled with random assignment allows us to eliminate these threats. 

5 major treats of external validity (generalizability) with experimental design: 
- Selection - to what social and psychological groups can a finding be generalized?
- Setting - can the results of a study also be applied to other settings? 
- History - can the findings be generalized to the past and to the future? 
- Effects of pre-testing - can it also be applied to people who are not pre-tested? 
- Effects of experimental arrangements - are the results the same for people who are not watched? (Hawthorne effect: awareness by people of being watched influenced results) 

An advantage of field experiments is their high ecological validity. 

In a laboratory experiment the researcher has a higher level of control over experimental arrangement, and this is likely to enhance the internal validity of the study and it will be more straightforward to replicate. 
However, there are some limitations: 
- External validity is likely to be difficult to establish 
- Often worked with volunteers, and volunteers differ from non-volunteers 
- Low ecological validity 

Quasi-experiment: a research design that is close to being an experiment but that does not meet the requirements fully and therefore does not exhibit complete internal validity. For example: 
- Not random assignment for group A or B because of important dependent variables 
- No control group 

A central feature of any experiment is the fact that it entails a comparison: at the very least it entails a comparison of results obtained by an experimental group with those engendered by a control group. 2 Cross-sectional design: comparison of more cases at a given point in time

### 2 Cross-sectional design: comparison of more cases at a given point in time 
Cross-sectional design entails the collection of data on more than one case (usually quite a lot more than one) and at a single point in time in order to collect a body of quantitative and quantifiable data in connection with two or more variables (usually quite more than two), which are then examined to detect patterns of association. 
- Replicability is likely to be present 
- Internal validity is typically weak 
- Ecological validity may be jeopardized 

Survey research = research that employs a cross-sectional design and in which data are collected by questionnaire or by structured interview 

Most quantitative business research employs a cross-sectional research design rather than an experimental one, because then it is possible to manipulate the variables in which we are interested. 

Qualitative research often entails a form of cross-sectional design, like unstructured interviewing or semi-structured interviewing with a number of people.

### 3 Longitudinal design: same sample is surveyed at different point in time (to map change) 
Longitudinal design: sample is surveyed and is then surveyed again on at least one further occasion However, they are very time consuming and expensive and therefore not often used in business research.

The longitudinal design is little different from cross-sectional research. However, because longitudinal research is done over a longer period of time more conclusions about causal inferences can be made.
There are two types of longitudinal design 
- Panel study: the same participants are used throughout a panel study 
- Cohort study: different participants (with certain characteristics, like just married) are used throughout a cohort study

### Case study design 
Case study entails the detailed and intensive analysis of a single case. A case can be 
- A single organization 
- A single location 
- A person 
- A single event 

Goal: concentrate on uniqueness of the case and to develop a deep understanding of its complexity 

What distinguishes a case study from other research designs is the focus on a bounded situation or system, an entity with a purpose and functioning parts. 
	➔ Case studies are often associated with qualitative methods 

With a case study, the case is an object of interest in its own right, and the researcher aims to provide an in-depth elucidation of it. 

Case study has a ideographic approach (highlights unique features of a case) instead of a nomothetic approach as for example cross-sectional designs that look for generating statements that apply regardless of time and place. 

Three different goals of case study 
- Intrinsic case studies : undertaken to gain insight into the particularities of a situation 
- Instrumental case studies : focus on using case as a means of understanding a broader issue 
- Multiple or collective case studies : focus on exploring a general phenomenon 

Deductive or inductive? Just like with cross-sectional design: 
- If case study is researched with qualitative research strategy, approach tends to be inductive. 
- If case study is researched with quantitative research strategy, approach tends to be deductive. 

Types of cases 
- Critical case - a case based on a hypothesis 
- Unique case - a common focus on clinical studies 
- Revelatory case - explore a new development that has not been researched before 
- Representative (or typical case) - explore the everyday situation 
- Longitudinal case - how situations change over time 

Multiple-case study designs have become increasingly common in business research. They allow the researcher to compare and contrast the findings deriving from each of the cases. 
	➔ With multiple-case study design, the emphasis is on individual cases; with a cross-sectional design, it is on the samples of cases.

### Comparative design 
Comparative design entails the study using more or less identical methods on two or more contrasting cases 
- May be realized in context of quantitative or qualitative research 
- There are at least two cases and data are collected from each, usually within a cross- sectional format 

Distinguish is made between: 
- Cross-cultural approaches (compare national management systems and local business customers in various countries) 
- Intercultural approaches (focus on study of interaction between people and organizations with different national/cultural backgrounds) 

In terms of issues of reliability, validity, replicability and generalizability, the comparative study is no different from the cross-sectional design. 
	➔ The comparative design is essentially two or more cross-sectional studies carried out at more or less the same point in time. 
The key to the comparative design is its ability to allow the distinguishing characteristics of two or more cases to act as a springboard for theoretical reflections about contrasting findings. 

Quantitative comparative design: often takes form of cross-sectional design Qualitative comparative design: often takes form of case study design (multiple) 
Qualitative comparative design: often takes form of case study design (multiple) 

### Level of analysis 
Research can be done on different levels, often revered as SOGI model: 
- Individuals (e.g. managers, employees, etc.) 
- Groups (e.g. HRM department, board of directors, etc.) 
- Organizations (e.g. workplace, salaries, etc.) 
- Societies (e.g. national, political context of the company) 

Often mixed methods research is used, where quantitative and qualitative methods are combined. 

### Bringing research strategy and research design together 
| Research design | Research strategy | Research strategy |
|---|---|---|
|  | Quantitative | Qualitative |
| Experimental | Typical form: Most researchers using an experimental design employ quantitative comparisons between experimental and control groups with regard to the dependent variable | No typical form: The Hawthorne experiments provide an example of experimental research design that gradually moved away from the 'test room method' towards the use of more qualitative methods |
| Cross-sectional | Typical form : Social survey research or structured observation on a sample at a single point in time. This can also include content analysis on a sample of documents. | Typical form : Qualitative interviews or focus groups at a single point in time. Can also be based upon qualitative content analysis of a set of documents relating to a single event or a specific period in time |
| Longitudinal | Typical form : Social survey research on a sample on more than one occasion or content analysis of documents relation to different time periods | Typical form : Ethnographic research over a long period, qualitative interviewing on more than one occasion, or qualitative content analysis of documents relating to different time periods. |
| Case study | Typical form : Social survey research on a single case with a view to revealing important features about its nature | Typical form : The intensive study by ethnography or qualitative interviewing of a single case, which may be an organization or individual. |
| Comparative | Typical form : Social survey research in which there is a direct comparison between two or more cases, including cross-cultural research. | Typical form : Ethnographic or qualitative interview research on two or more cases where some comparison is sought between them. |

# 8. The nature of quantitative research
### Introduction 
Quantitative research is a distinctive research strategy. It's about entailing the collection of numerical data and exhibiting view of the relationship between theory and research as deductive, a predilection of a natural science approach (and of positivism in particular), and as having an objectivist conception of social reality. 

### The main steps in quantitative research 
Quantitative research is a linear series of steps moving from theory to conclusions, but the process described in the figure is an ideal type from which there may be many departures. 

Good deal of quantitative research does not require the specification of hypothesis. 

For variables that are not readily measured in numbers, quantification will entail coding the information (transforming it into numbers). 

A significant part of the research process involves convincing others of the significance and validity of one's findings. 

### Concepts and their measurements 
Concepts are building blocks of theory and represent points around which business research is conducted. Bulmer: Concepts are categories for organization of ideas and observations. (Concept = intelligence and IQ = measurement of the concept intelligence). 
If a concept is to be employed in quantitative research, it will have to be measured. Once they are measured, concepts can be in the form of independent or dependent variables. 
	➔ In other words, concepts may provide an explanation of a certain aspect of the social world (independent variables), or they stand for things we want to explain (dependent variables). 

Measures are quantities. The measurement process entails the search for indicators. Three reasons for preoccupation with measurement in quantitative research: 
- Measurement allows us to delineate fine differences between people, organizations, or other entities in terms of the characteristic in question.
- Measurement gives us a consistent device or yardstick for making such distinctions. A measurement device provides a consistent instrument for gauging differences. This consistency relates to our ability to be consistent over time and with other researchers
- Measurement provides the basis for more precise estimates of the degree of relationship between concepts

In order to provide a measure of concept (operational definition), it is necessary to have an indicator or indicators that will stand for the concept. There are many ways in which indicators can be devised: 
- Through a question that is part of a structured interview schedule or self-completion questionnaire 
- Through the recording of individuals' behavior using a structured observation schedule 
- Through the use of existing surveys 
- Through an examination of mass media content by way of content analysis 

The use of multiple-indicator measures reflects the fact that some phenomena are multi-dimensional. The main reason for using a multiple-indicator measure of a concept is a recognition that there are potential problems with a reliance on just a single indicator: 
- A single indicator will incorrectly classify many individuals or organizations. 
- One indicator may capture only a portion of the underlying concept or to be too general. 
- You can make much finer distinctions.

### Reliability of measures 
Reliability refers to the consistency of a measure of a concept. The following are three prominent factors involved when considering whether a measure is reliable: 
- Stability: entails asking whether a measure is stable over time, so that we can be confident that the results relating to that measure for a sample of respondents do not fluctuate
	- Test-retest method 
	- Involves administering a test or measure on one occasion and then re-administering it to the sample on another occasion 
	- We should expect to find a high correlation between the two occasions: correlation is a measure of the strength of the relationship between two variables 
- Internal reliability: key issue whether the indicators that make up the scale or index for a concept are consistent among themselves 
	- Whether or not respondents' scores on any one indicator tend to be related to their scores on the other indicators associated with that concept 
	- Cronbach's alpha is used as test of internal reliability. It essentially calculates the average of all split-half reliability coefficients. A computed alpha coefficient will vary between 1 (perfect internal reliability) and 0 (no internal reliability) the figure 0.8 is rule of thumb to denote an acceptable level of internal reliability. 
- Inter-rater reliability: when a great deal of subjective judgement is involved in the recording of observations or the translation of data into categories 
	- Where more than one rater is involved in such activities, there is the possibility that there is a lack of consistency in their decisions.

### Validity of measures 
Validity refers to the issue of whether or not an indicator (or set of indicators) that is devised to gauge a concept really measures that concept. 
Here, validity is being used as a shorthand for what was referred to as measurement validity.
A distinction is made between number of types of validity:
	- Face validity - the measure apparently reflects the content of the concept in question. People might be asked to act as judges to determine whether or not on the face of it the measure seems to reflect the concept concerned. It is an essentially intuitive process. 
	- Concurrent validity - the researcher employs a criterion on which cases are known to differ and that is relevant to the concept in question 
	- Predictive validity - the researcher uses a future criterion measure, rather than a contemporary one, as in the case of concurrent validity 
	- Convergent validity - comparing it to measures of the same concept developed through other methods 
	- Discriminant validity - ensuring that when a measure is used for one construct it is different in terms of its content from a measure used to measure another construct

### The connection between reliability and validity
It should be borne in mind that, although reliability and validity are analytically distinguishable, they are related because validity presumes reliability. This means that if your measure is not reliable, it cannot be valid. 

### The main preoccupations of quantitative researchers 
Quantitative research can be characterized as exhibiting certain preoccupations:
- Measurement 
	- From position of quantitative research, measurement carries some advantages. 
	- Issues of reliability and validity are a concern for quantitative researchers. 
- Causality
	- There is a very strong concern with causal explanation in most quantitative research. Quantitative researchers are rarely content merely to describe how things are, but are keen to say why things are the way they are.
	- Researchers are likely to want to explain the phenomenon, which means examining its causes.
	- The idea of independent and dependent variables reflect the tendency to think in terms of causes and effects (independent variable = manipulated).
	- A criterion of good quantitative research is frequently the extent to which there is confidence in the researcher's causal inferences. 
- Generalization
	- In quantitative research the researcher usually hopes to be able to say that his/her findings can be generalized beyond the confines of the particular context in which the research was conducted (probability sampling) 
- Replication
	- The results of a piece of research should be unaffected by the researcher's special characteristics or expectations.
	- It is often regarded as important that the researcher spells out clearly his or her procedures so that they can be replicated by others, even if the research does not end up being replicated.

### The critique of quantitative research 
Four criticisms of quantitative research, which revolve around the view that a natural science model is inappropriate for studying the social world.
- Quantitative researchers fail to distinguish people and social institutions from 'the world of nature'.
- The measurement process possesses an artificial and spurious sense of precision and accuracy.
- The reliance on instruments and procedures hinders the connection between research and everyday life.
- The analysis of relationships between variables creates a static view of social life that is independent of people's lives.

### Is it always like this? 
One of the problems with characterizing any research strategy, research design, or research method is that to a certain extent one is always outlining an ideal-typical approach. One tends to create something that represents that strategy, design or method, but that may not be reflected in its entirely research practice. This gap between the ideal type and actual practice can arise as a result of at least two major considerations. 
- It arises because those of us write about and teach research methods cannot cover every eventuality that can arise in the process of business research. 
- It arises because to a very large extent when writing about and teaching research methods, we are essentially providing an account of good practice. 

### Reverse operationism 
Deductive view of research ('operationism') neglects the fact that measurement entails much more of an inductive element. Sometimes, measures are developed that in turn lead to conceptualization. 

### Reliability and validity testing 
Second reason why the gap between the ideal type and actual research practice can arise is because researchers do not always follow recommended practices. The reasons why the procedures for determining stability and validity are rarely used are almost certainly the cost and time that are likely to be involved. 

### Sampling 
Good practice is strongly associated with the use of random or probability samples. However, quite a lot of research is based on non-probability samples due to the impossibility or extreme difficulty of obtaining probability samples. Another reason is that the time and cost involved in securing a probability sample are too great relative to the level of resources available and sometimes the opportunity to study a certain group presents itself and represents too good an opportunity to miss 

# 15. Quantitative data analysis 
### Introduction 
Quantitative data analysis occurs typically at a late stage in the process and is a distinct stage, but that does not mean that you should not be considering how you will analyse your data until then. 
You should be fully aware of what techniques you will apply during the data analysis in a fairly early stage for two main reasons:
- You cannot apply just any technique to any variable.
- The size and nature of your sample are likely to impose limitations on the kinds of techniques you can use. 

Decisions that you make at an early stage in the research process, such as kinds of data you collect and size of sample, will have implications for the sorts of analysis that you will be able to conduct. 

### A small research project 
Missing data arise when respondents fail to reply to a question - either by accident or because they do not want to answer the question (coded as a zero (0)). 

### Types of variable 
There are four main types of variables:
- Interval / ratio variables: variables where the distances between the categories are identical across the range of categories (internal variables have a fixed zero point)
- Ordinal variables: variables whose categories can be rank ordered but the distances between the categories are not equal across the range
- Nominal variables: variables also known as categorical variables, comprise categories that cannot be rank ordered
- Dichotomous variables: variables that contain data that have only two categories 

### Univariate analysis 
Univariate analysis refers to the analysis of one variable at a time. 

### The commonest approaches 
- Frequency tables: provides the number of people and the percentage belonging to each of the categories for the variable in question 
	- Can be used in relation to all the different types of variable 
- Diagrams: most frequently used methods of displaying quantitative data 
	- Relatively easy to interpret and understand 
	- Bar chart of pie chart: nominal or ordinal variables 
	- Histogram: interval/ratio variables 
- Measures of central tendency: encapsulate in one figure a value that is typical for a distribution of values. In effect, we are seeking out an average for a distribution, but in quantitative data analysis three different forms of average are recognized:
	- Arithmetic mean: add all values in a distribution and then divide by the number of values, vulnerable to outliers 
		-  Internal/ratio variables (ordinal) 
	- Median: mid-point in a distribution of values, it is derived by arraying all values in a distribution from smallest to largest and finding the middle point
		-  Internal/ratio & ordinalAnother measure of dispersion is standard deviation: average amount of variation around mean, calculated by taking differences between each value in a distribution and the mean and then dividing the total of differences by number of values
	- Mode: value that occurs most frequently in a distribution
- Measures of dispersion: amount of variation in a sample can be just as interesting as providing estimates of the typical value of a distribution
	- Most obvious way of measuring dispersion is by the range.
	- Another measure of dispersion is standard deviation: average amount of variation around mean, calculated by taking differences between each value in a distribution and the mean and then dividing the total of differences by number of values
	- Popular type of figure is the boxplot, which provides an indication of both central tendency (median) and dispersion (range) and indicates the outliers

### Bivariate analysis
Bivariate analysis is concerned with the analysis of two variables at a time to uncover whether the two variables are related. Exploring relationships between variables means searching for evidence that the variation in one variables coincides with variation in another variable. A variety of techniques is available for examining relationships, but use depends on nature of two variables being analyzed. 

An important point to bear in mind about all of the methods for analyzing relationships between variables is that it is precisely relationships that they uncover.

Contingency tables are probably the most flexible of all methods of analyzing relationships in that they can be employed in relation to any pair of variables. A contingency table is like a frequency table, but it allows two variables to be simultaneously analyzed so that relationships between the two variables can be examined. Users of contingency tables often present the presumed independent variable as column variable and dependent variable as rows variable.

Pearson's r is a method for examining relationships between interval/ratio variables. 
- The coefficient will almost certainly lie between 0 (no relationship) and 1 or -1 (perfect relationship) - this indicates the strength of a relationship.
- The closer the coefficient is to 1, the stronger the relationship. 
- The coefficient will be positive or negative - this indicates the direction of a relationship. In order to be able to use Pearson's r, the relationship between two variables must be broadly linear - that is, when plotted on a scatter diagram, the values of two variables approximate to a straight line.

Phi and Cramér's V are two closely related statistics:
- The phi coefficient is used for the analysis of the relationship between two dichotomous variables. It results in a computed statistic that varies between 0 and +1 or -1. 
- Cramér's V uses a similar formula to phi and can be employed with nominal variables. However, this statistic can take on only a positive value, so that it can give an indication only of the strength of the relationship between two variables, not the direction. It is usually reported along with a contingency table and chi square test.

If you need to examine the relationship between an interval/ratio variable and a nominal variable, and if the latter can be relatively unambiguously identified as the independent variable, a potentially fruitful approach is to compare the means of the interval/ratio variable for each subgroup of the nominal variable. This procedure is often accompanied by a test of association between variables called eta. This statistic expresses the level of association between the two variables and will always be positive.

### Multivariate analysis
Multivariate analysis entails the simultaneous analysis of three or more variables. There are three main contexts within which multivariate analysis might be employed.
- Could the relationship be spurious? 
	- Spurious relationship exists when there appears to be a relationship between two variables, but the relationship is not real: it is being produced because each variable is itself related to a third variable.
- Could there be an intervening variable? 
	- An intervening variable allows us to answer questions about the bivariate relationship between variables
	- It suggests that the relationship between the two variables is not a direct one.
- Could a third variable moderate the relationship?
	- Does the relationship between two variables hold for men but not for woman? If it does, the relationship is said to be moderated by gender.

### Statistical significance
One difficulty with working on data deriving from a sample is that there is often the lingering worry that, your findings will not be generalizable to the population from which the sample is drawn. What you can do to provide an indication of how confident you can be that your findings can be generalized to the population from which that sample was selected -> statistical significance.

A test of statistical significance allows the analyst to estimate how confident he or she can be that the results deriving from a study based on a randomly selected sample are generalizable to the population from which the sample was drawn. It also tells us about the risk of concluding that there is in fact a relationship in the population when there is no such relationship in the population.

Common structure of all of the tests:
- Set up a null hypothesis (no relationship in the population between two variables) 
- Establish the level of statistical significance that you find acceptable = measure of the degree of risk that you might reject the null hypothesis when you should support it. Levels are expressed as probability levels. (p < 0,05 is acceptable) 
- Determine the statistical significance of your findings = use a statistical test like chi-square If p <0,05, you would reject the null hypothesis. Therefore, you are implying that the results are unlikely to have occurred by **chance**.

There are in fact two types of error that can be made when inferring statistical significance: 

Chi-square test: applied to contingency tables and allows us to establish how confident we can be that there is a relationship between two variables in the population. 
-  Test works by calculating for each cell in the table an expected frequency of value - that is, one that would occur on the basis of chance alone. 

Examining the statistical significance of a computed correlation coefficient, which is based on a randomly selected sample, provides information about the likelihood that the coefficient will be found in the population from which the sample was taken. Whether a correlation coefficient is statistically significant or not will be affected by two factors: 
- Size of computed coefficient 
- Size of sample 

Comparing means and statistical significance entails treating the total amount of variation in the dependent variable as made up of two types: variation within the four subgroups that make up the independent variable, and variation between them. The latter is often called explained variance and former the error variance.
